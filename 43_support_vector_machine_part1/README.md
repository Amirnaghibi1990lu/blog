This week, let's have a look of the popular [support vector machine](https://en.wikipedia.org/wiki/Support_vector_machine) (SVM). It can be used both in classification and regression problems. 

Let's start with a brief history of SVM. 

## Brief history of SVM
**1960** - Research started in 1960s.  
**1963-1964** - Study of the Margin.  
**1964** - Radial Baisis Function (RBF) Kernels.    
**1965** - Optimization formulation. 
**1971** - Kernels.  
**1992** - Modern SVMs from Boser, Guyon, and Vapnik ("[A training algorithm for optimal margin classifiers](http://w.svms.org/training/BOGV92.pdf)")

We can see most of the research happens around 1960s - 1970s, and then SVM becomes famous when it gives comparable accuracy to the Artificial Neural Networks with elaborated features in handwriting recognition.   

In the next session, we will explore the idea behind the SVMs. After you get the basic idea, you will understand why it is called support vector machine.  

## Intuitive Support Vector Machines  

<img src="https://raw.githubusercontent.com/qingkaikong/blog/master/43_support_vector_machine_part1/figures/figure_1.jpg" width="600"/> 